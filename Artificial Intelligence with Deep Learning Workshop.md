# Artificial Intelligence with Deep Learning Workshop

**Overview**

Welcome to the Artificial Intelligence with Deep Learning Workshop, where you will embark on a transformative journey into the world of AI and deep learning. This intensive workshop will equip you with the essential knowledge and skills to develop neural networks from scratch, create powerful models, and deploy them effectively. As AI continues to revolutionize our daily lives, deep learning stands at the forefront, driving remarkable advancements and enabling groundbreaking applications.

**Course Description**

Deep learning, a subset of machine learning, emulates how humans learn by example. Through this course, you will explore how deep learning empowers driverless cars to recognize stop signs, voice control in consumer devices, and achieve unprecedented accuracy in various tasks. The course delves into the world of neural network architectures and data utilization, enabling you to harness the full potential of this cutting-edge technology.

**Learning Objectives**

By the end of this comprehensive Artifical Intelligence and Deep Learning Course, you will:

1. **Understand the Basics of Deep Learning:** Gain a solid foundation in deep learning principles, methodologies, and applications.

2. **Use Tuning Models:** Master the art of fine-tuning models for optimal performance and accuracy.

3. **Create Convolutional Neural Networks:** Develop expertise in constructing convolutional neural networks for image and video analysis.

4. **Implement Recurrent Neural Networks:** Learn how to utilize recurrent neural networks for sequential data and time-series analysis.

5. **Develop and Deploy Models:** Acquire practical skills in building and deploying deep learning models in real-world scenarios.

6. **Work with Python and Jupyter Notebooks:** Familiarize yourself with Python and Jupyter Notebooks, industry-preferred tools for AI development.

7. **Embrace Best Practices:** Gain insights into industry best practices to ensure effective and efficient AI solutions.

**Audience Prerequisites**

This AI and deep learning course is designed for the following professionals:

- Data Scientists
- Modelers
- Engineers interested in picking up AI skills
- CIOs
- CTOs
- IT Leaders
- Product Owners and Managers
- Developers and Application Team Leads
- Project and Program Managers
- Software Managers
- IT Operations Staff

**Course Outline**

**Part 1: Introduction to Deep Learning**

- What is a neural network?
- Supervised Learning with Neural Networks
- Why is Deep Learning taking off?

**Part 2: Neural Networks Basics**

- Binary Classification
- Logistic Regression
- Logistic Regression Cost Function
- Gradient Descent
- Derivatives
- More Derivative Examples
- Computation graph
- Derivatives with a Computation Graph
- Logistic Regression Gradient Descent
- Gradient Descent on m Examples
- Vectorization

**Part 3: Shallow Neural Networks**

- Neural Networks Overview
- Neural Network Representation
- Computing a Neural Network's Output
- Vectorizing across multiple examples
- Explanation for Vectorized Implementation
- Activation functions
- Why do you need non-linear activation functions?
- Derivatives of activation functions
- Gradient descent for Neural Networks

**Part 4: Deep Neural Networks**

- Deep L-layer neural network
- Forward Propagation in a Deep Network
- Getting your matrix dimensions right
- Why deep representations?
- Building blocks of deep neural networks
- Forward and Backward Propagation
- Parameters vs. Hyperparameters

**Part 5: Practical Aspects of Deep Learning**

- Train / Dev / Test sets
- Bias / Variance
- Basic Recipe for Machine Learning
- Regularization
- Why regularization reduces overfitting?
- Dropout Regularization
- Understanding Dropout
- Other regularization methods
- Normalizing inputs
- Vanishing / Exploding gradients
- Weight Initialization for Deep Networks
- Numerical approximation of gradients
- Gradient checking
- Gradient Checking Implementation Notes

**Part 6: Optimization Algorithms**

- Mini-batch gradient descent
- Understanding mini-batch gradient descent
- Exponentially weighted averages
- Understanding exponentially weighted averages
- Bias correction in exponentially weighted averages
- Gradient descent with momentum
- RMSprop
- Adam optimization algorithm
- Learning rate decay
- The problem of local optima

**Part 7: Hyperparameter Tuning, Batch Normalization, and Programming Frameworks**

- Tuning process
- Using an appropriate scale to pick hyperparameters
- Hyperparameters tuning in practice: Pandas vs. Caviar
- Normalizing activations in a network
- Fitting Batch Norm into a neural network
- Why does Batch Norm work?
- Batch Norm at test time
- Softmax Regression
- Training a softmax classifier
- Deep learning frameworks
- TensorFlow

**Part 8: Foundations of Convolutional Neural Networks**

- Computer Vision
- Edge Detection Example
- More Edge Detection
- Padding
- Strided Convolutions
- Convolutions Over Volume
- One Layer of a Convolutional Network
- Simple Convolutional Network Example
- Pooling Layers
- CNN Example
- Why Convolutions?
- Deep convolutional models: case studies
- Classic Networks
- ResNets
- Why ResNets Work
- Networks in Networks and 1x1 Convolutions
- Inception Network Motivation
- Inception Network
- Using Open-Source Implementation
- Transfer Learning
- Data Augmentation
- State of Computer Vision

**Part 9: Recurrent Neural Networks**

- Why sequence models
- Notation
- Recurrent Neural Network Model
- Backpropagation through time
- Different types of RNNs
- Language model and sequence generation
- Sampling novel sequences
- Vanishing gradients with RNNs
- Gated Recurrent Unit (GRU)
- Long Short Term Memory (LSTM)
- Bidirectional RNN
- Deep RNNs

**Part 10: Natural Language Processing & Word Embeddings**

- Word Representation
- Using word embeddings
- Properties of word embeddings
- Embedding matrix
- Learning word embeddings
- Word2Vec
- Negative Sampling
- GloVe word vectors
- Sentiment Classification
- Debiasing word embeddings
- Sequence models & Attention mechanism
- Basic Models
- Picking the most likely sentence
- Beam Search
- Refinements to Beam Search
- Error analysis in beam search
- Bleu Score (optional)
- Attention Model Intuition
- Attention Model
- Speech recognition
- Trigger Word Detection

**Part 11: ML Strategy**

- Why ML Strategy
- Orthogonalization
- Single number evaluation metric
- Satisficing and Optimizing metric
- Train/dev/test distributions
- Size of the dev and test sets
- When to change dev/test sets and metrics
- Why human-level performance?
- Avoidable bias
- Understanding human-level performance
- Surpassing human-level performance
- Improving your model performance
- Carrying out error analysis
- Cleaning up incorrectly labeled data
- Build your first system quickly, then iterate
- Training and testing on different distributions
- Bias and Variance with mismatched data distributions
- Addressing data mismatch
- Transfer learning
- Multi-task learning
- What is end-to-end deep learning?
- Whether to use end-to-end deep learning

Join us in this transformative journey and unlock the true potential of Artificial Intelligence and Deep Learning!
